{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic MNIST MLP with VMAP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJHayfM2DdmaLLDQspfA4Z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7kcOECcnUdc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ad401ec-067d-49be-a03d-bd010ec95554"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "from jax import grad,vmap,jit\n",
        "import numpy as onp\n",
        "from jax import random\n",
        "key = random.PRNGKey(0)\n",
        "import timeit\n",
        "\n",
        "from jax import experimental \n",
        "from jax.experimental import *\n",
        "from jax.numpy import linalg\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as py\n",
        "from jax import device_put\n",
        "\n",
        "import itertools\n",
        "\n",
        "from jax.experimental import optimizers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZj4wege-NdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.config.experimental.set_visible_devices([], \"GPU\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wP8khoKYQ8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tanh_act(x): \n",
        "    return np.tanh(x)\n",
        "def sigmoid_act(x): \n",
        "  return jax.nn.sigmoid(x)\n",
        "def softmax_act(x): \n",
        "    return np.exp(x)/(np.sum(np.exp(x)))\n",
        "def binary_crossentropy(x,y): #x=input, y= target\n",
        "    return -y*np.log(x)-(1-y)*np.log(1-x)\n",
        "def relu_act(x): \n",
        "  return jax.nn.relu(x)\n",
        "def normalize(x): \n",
        "  return jax.nn.normalize(x,axis=0)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZH6194anX3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_parameters(shapes):  \n",
        "    onp.random.seed(1000)\n",
        "    trainable_v=[[]]\n",
        "    #first layer\n",
        "    trainable_v[0].append(onp.random.randn(shapes[0],shapes[0])) #input\n",
        "    trainable_v[0].append( onp.random.randn (shapes[0])) #bbias \n",
        "    for i in range(1,len(shapes)): \n",
        "      trainable_v.append([]) #creates new layer?\n",
        "      trainable_v[i].append(onp.random.randn(shapes[i],shapes[i-1]))\n",
        "      trainable_v[i].append(onp.random.randn(shapes[i]))\n",
        "    return trainable_v\n",
        "\n",
        "def NLL(x,y): \n",
        "    return -np.log(x[np.argmax(y)]) #assuming one hot\n",
        "\n",
        "def BCE_loss(params,i,t): \n",
        "  pred=dense_network(params,i)\n",
        "  final=binary_crossentropy(pred,t) \n",
        "  return final\n",
        "\n",
        "#assumes the gradient input has shape [batch_size,weight matrix]\n",
        "#this is why the np.mean is there.\n",
        "def update_weights(params, gradient ,lr=1.0): \n",
        "  for i in range(len(params)): #iterate through the layer. \n",
        "    params[i][0]=params[i][0]-(lr*np.mean(gradient[i][0],axis=0))\n",
        "    params[i][1]=params[i][1]-(lr*np.mean(gradient[i][1],axis=0))\n",
        "  return params\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYOwmP4ZptfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Single Network\n",
        "\n",
        "def dense_network_list(params,input):\n",
        "  l1=np.dot(input,params[0][0].T)+params[0][1]\n",
        "  l1=sigmoid_act(l1)\n",
        "  l2=np.dot(l1,params[1][0].T)+params[1][1] \n",
        "  l2=sigmoid_act(l2)\n",
        "  l3=np.dot(l2,params[2][0].T)+params[2][1]\n",
        "  l3=softmax_act(l3)\n",
        "  return l3\n",
        "\n",
        "\n",
        "\n",
        "def NLL_loss(params,i,t): #loss function only accepts one sample at a time, however I will attempt to remedy this by vmap\n",
        "  pred=dense_network_list(params,i)\n",
        "  final=jit(NLL)(pred,t)\n",
        "  return final\n",
        "\n",
        "gradient=grad(NLL_loss)\n",
        "\n",
        "vmap_backprop = vmap(gradient,in_axes=(None,0,0))\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvh8yrh7Eg0V",
        "colab_type": "text"
      },
      "source": [
        "###Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX3p3Lv3DBm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data,train_labels),(test_data,test_labels)=tf.keras.datasets.mnist.load_data()\n",
        "train_data=train_data.reshape(60000,784).astype('float32')\n",
        "test_data=test_data.reshape(10000,784).astype('float32')\n",
        "train_labels=to_categorical(train_labels)\n",
        "test_labels=to_categorical(test_labels)\n",
        "train_data=train_data/255.0\n",
        "test_data=test_data/255.0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjBzldCv-0W9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=device_put(train_data, jax.devices('gpu')[0])\n",
        "train_labels=device_put(train_labels, jax.devices('gpu')[0])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65SB9ADdEj11",
        "colab_type": "text"
      },
      "source": [
        "###Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U--AzFWTC9sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = init_parameters([784,50,10])"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sgw3xvYRfAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "3b4eec90-4212-49c0-a51e-af4b22040ce5"
      },
      "source": [
        "dense_jit=jit(dense_network_list) #speed up\n",
        "jit_backprop=jit(vmap_backprop)\n",
        "jit_update_weights=jit(update_weights)\n",
        "\n",
        "ctr=0\n",
        "start_time = timeit.default_timer()\n",
        "for i in range(10): #epochs\n",
        "  for j in range(300): #number of batches to iterate.\n",
        "    \n",
        "    dparams=jit_backprop(parameters,train_data[ctr:ctr+100],train_labels[ctr:ctr+100]) #The last value is batch size\n",
        "    parameters= jit_update_weights(parameters,dparams,lr=1.0)\n",
        "    ctr=ctr+100\n",
        "    #print (j)\n",
        "    if ctr+10>30000:\n",
        "      ctr=0\n",
        "\n",
        "  pred=np.argmax(dense_jit(parameters,train_data[30000:30100]),axis=1)\n",
        "  targets=np.argmax(train_labels[30000:30100],axis=1)\n",
        "  print (f'epoch: ', i+1)\n",
        "  print(len(np.where(pred == targets)[0])/100)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print (elapsed)  "
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1\n",
            "0.73\n",
            "epoch:  2\n",
            "0.75\n",
            "epoch:  3\n",
            "0.79\n",
            "epoch:  4\n",
            "0.84\n",
            "epoch:  5\n",
            "0.84\n",
            "epoch:  6\n",
            "0.86\n",
            "epoch:  7\n",
            "0.86\n",
            "epoch:  8\n",
            "0.87\n",
            "epoch:  9\n",
            "0.89\n",
            "epoch:  10\n",
            "0.88\n",
            "10.315771481999946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_pkLvMWRu6o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93fd3a42-9a8f-4393-aa59-4ed8611ccc11"
      },
      "source": [
        "#full test: \n",
        "pred_1=np.argmax(dense_jit(parameters,test_data),axis=1)\n",
        "target_1=np.argmax(test_labels,axis=1)\n",
        "print(len(np.where(pred_1 == target_1)[0])/10000 *100)\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91.05\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}