{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cross Stitch Network Implementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPor5f/xu3KHB4i1g0vIioi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIDODhkzIGZ2",
        "colab_type": "text"
      },
      "source": [
        "#Cross-Stitch Network using Jax\n",
        "\n",
        "Implementation of: \n",
        "---\n",
        "Misra, I., Shivastava, A., Gupta, A., Herbert,M. (2016). Cross-Stitch Networks for Multi-Task Learning. \n",
        "\n",
        "Misra et al combined the activation map of a layer of one network to another network using a  learnable parameters $\\alpha$. \n",
        "\n",
        "Overview:\n",
        "--- \n",
        "Two FC networks with [60,20,10] stucture are trained on either MNIST or Fashion MNIST. \n",
        "The two networks are combined with $\\alpha$ to form a network of shape [120,40,10] and trained on a fraction of a combined dataset. \n",
        "\n",
        "Result is a combined network that can classify mnist and fashion mnist with similar accuracy to the networks on their own. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLZL18DPJ0XG",
        "colab_type": "text"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkbVO1rW-dDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random as orandom\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad,vmap,jit\n",
        "import numpy as onp\n",
        "from jax import random\n",
        "key = random.PRNGKey(0)\n",
        "import timeit\n",
        "\n",
        "from jax import experimental \n",
        "from jax.experimental import *\n",
        "from jax.numpy import linalg\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as py\n",
        "from jax import device_put\n",
        "\n",
        "import itertools\n",
        "import random as orandom\n",
        "from jax.experimental import optimizers\n",
        "from sklearn.utils import shuffle #to help with shuffling of combined dataset."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5ndvrsI-vED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.config.experimental.set_visible_devices([], \"GPU\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L2QuGyyIPGT",
        "colab_type": "text"
      },
      "source": [
        "##Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BqvGfaKHmWB",
        "colab_type": "text"
      },
      "source": [
        "###Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2CVL-ku-vXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_act(x): \n",
        "  return jax.nn.sigmoid(x)\n",
        "def softmax_act(x): \n",
        "    return jax.nn.softmax(x)\n",
        "def binary_crossentropy(x,y): #x=input, y= target\n",
        "    return -y*jnp.log(x)-(1-y)*jnp.log(1-x)\n",
        "def relu_act(x): \n",
        "  return jax.nn.relu(x)\n",
        "def NLL(x,y): \n",
        "  return -jnp.log(x[jnp.argmax(y)]) #assuming one hot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEG_6FP8HqH6",
        "colab_type": "text"
      },
      "source": [
        "###Initialization function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwy_Ookk5E65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_parameters_nobias(shapes,input_shape=784):      \n",
        "    trainable_v=[[]]\n",
        "    #first layer\n",
        "    trainable_v[0].append(onp.random.randn(shapes[0],input_shape)/10) #input\n",
        "    trainable_v[0].append( onp.zeros (shapes[0]))\n",
        "    for i in range(1,len(shapes)): \n",
        "      trainable_v.append([]) \n",
        "      trainable_v[i].append(onp.random.randn(shapes[i],shapes[i-1])/10)\n",
        "      trainable_v[i].append(onp.zeros(shapes[i]))\n",
        "    trainable_v[i][1] =onp.zeros(shapes[i]) #the last layer will have 0 bias to allow for concatenation \n",
        "    return trainable_v\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoK0r_mVH8Wd",
        "colab_type": "text"
      },
      "source": [
        "###Update Weight Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g3j21Kf_mu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#assumes the gradient input has shape [batch_size,weight matrix]\n",
        "def update_weights(params, gradient ,lr=1.0): \n",
        "  for i in range(len(params)): #iterate through the layer. \n",
        "    params[i][0]=params[i][0]-(lr*jnp.sum(gradient[i][0],axis=0))\n",
        "    params[i][1]=params[i][1]-(lr*jnp.sum(gradient[i][1],axis=0))\n",
        "  return params"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js3qYAK6H5_8",
        "colab_type": "text"
      },
      "source": [
        "##Network and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17A6-dab_nUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dense_network_list(params,input):\n",
        "  l1=jnp.dot(input,params[0][0].T)+params[0][1]\n",
        "  l1=sigmoid_act(l1)\n",
        "  l2=jnp.dot(l1,params[1][0].T)+params[1][1] \n",
        "  l2=sigmoid_act(l2)\n",
        "  l3=jnp.dot(l2,params[2][0].T)#+params[2][1]\n",
        "  l3=softmax_act(l3)\n",
        "  return l3\n",
        "\n",
        "def NLL_loss(params,i,t): #loss function only accepts one sample at a time, however I will attempt to remedy this by vmap\n",
        "  pred=dense_network_list(params,i)\n",
        "  final=NLL(pred,t)\n",
        "  return final\n",
        "\n",
        "gradient=grad(NLL_loss)\n",
        "\n",
        "vmap_backprop = vmap(gradient,in_axes=(None,0,0))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN5VY2Y1KBXn",
        "colab_type": "text"
      },
      "source": [
        "##Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkcuiFtFCiFI",
        "colab_type": "text"
      },
      "source": [
        "Load Data, MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4khAxPE_qVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(mnist_train_data,mnist_train_labels),(mnist_test_data,mnist_test_labels)=tf.keras.datasets.mnist.load_data()\n",
        "mnist_train_data=mnist_train_data.reshape(60000,784).astype('float32')\n",
        "mnist_test_data=mnist_test_data.reshape(10000,784).astype('float32')\n",
        "mnist_train_labels=to_categorical(mnist_train_labels)\n",
        "mnist_test_labels=to_categorical(mnist_test_labels)\n",
        "mnist_train_data=mnist_train_data/255.0\n",
        "mnist_test_data=mnist_test_data/255.0\n",
        "mnist_train_data=device_put(mnist_train_data, jax.devices('gpu')[0])\n",
        "mnist_train_labels=device_put(mnist_train_labels, jax.devices('gpu')[0])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-LfF8GNOaRz",
        "colab_type": "text"
      },
      "source": [
        "Load Data Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HZL1hbvCnEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(fashion_train_data,fashion_train_labels),(fashion_test_data,fashion_test_labels)=tf.keras.datasets.fashion_mnist.load_data()\n",
        "fashion_train_data=fashion_train_data.reshape(60000,784).astype('float32') /255.0\n",
        "fashion_test_data=fashion_test_data.reshape(10000,784).astype('float32')/255.0\n",
        "fashion_train_labels=to_categorical(fashion_train_labels) \n",
        "fashion_test_labels=to_categorical(fashion_test_labels) \n",
        "fashion_train_data=device_put(fashion_train_data, jax.devices('gpu')[0])\n",
        "fashion_train_labels=device_put(fashion_train_labels, jax.devices('gpu')[0])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_wl56CyItQE",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ve2DCtK4lC5",
        "colab_type": "text"
      },
      "source": [
        "###Initialize parameters for MNIST Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu4-yKmBD0X7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onp.random.seed(1000)\n",
        "parameters_mnist = init_parameters_nobias([60,20,10],input_shape=784)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsi4W3HN8UiZ",
        "colab_type": "text"
      },
      "source": [
        "###Train First Network on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbeOndIW4r7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6b106d46-9e44-4966-e79e-34fb3b165e44"
      },
      "source": [
        "dense_jit=jit(dense_network_list)\n",
        "jit_backprop=jit(vmap_backprop)\n",
        "jit_update_weights=jit(update_weights)\n",
        "\n",
        "ctr=0\n",
        "start_time = timeit.default_timer()\n",
        "for i in range(5): #epochs\n",
        "  for j in range(500): #number of batches to iterate.\n",
        "    \n",
        "    dparams=jit_backprop(parameters_mnist,mnist_train_data[ctr:ctr+100],mnist_train_labels[ctr:ctr+100]) #The last value is batch size\n",
        "    parameters_mnist= jit_update_weights(parameters_mnist,dparams,lr=0.01)\n",
        "    ctr=ctr+100\n",
        "    if ctr+100>50000:\n",
        "      ctr=0\n",
        "  pred=dense_jit(parameters_mnist,mnist_train_data[50000:50100])\n",
        "  pred=jnp.argmax(pred,axis=1)\n",
        "\n",
        "  targets=jnp.argmax(mnist_train_labels[50000:50100],axis=1)\n",
        "  print (f'epoch: ', i+1)\n",
        "  print(f'Validation Accuracy: ', len(jnp.where(pred == targets)[0])/100*100)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print (f'elapsed time: ', elapsed, 's')  "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1\n",
            "Validation Accuracy:  88.0\n",
            "epoch:  2\n",
            "Validation Accuracy:  93.0\n",
            "epoch:  3\n",
            "Validation Accuracy:  96.0\n",
            "epoch:  4\n",
            "Validation Accuracy:  97.0\n",
            "epoch:  5\n",
            "Validation Accuracy:  98.0\n",
            "elapsed time:  13.200043748999633 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8feO5Z_U8Xor",
        "colab_type": "text"
      },
      "source": [
        "####Test MNIST network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5XPNuIM5N6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "579e06a3-02c2-4e71-9e25-ce5899e68e2a"
      },
      "source": [
        "#Test: \n",
        "pred_1=dense_jit(parameters_mnist,mnist_test_data)\n",
        "pred_1=jnp.argmax(pred_1,axis=1)\n",
        "target_1=jnp.argmax(mnist_test_labels,axis=1)\n",
        "print(f'Test Accuracy:',len(jnp.where(pred_1 == target_1)[0])/10000 *100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 95.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fY4ej4SOCXk",
        "colab_type": "text"
      },
      "source": [
        "###Second Network for Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DeXsfa8dDdE",
        "colab_type": "text"
      },
      "source": [
        "###Initialize parameters for Fashion MNIST Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3IIuVnM8z1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onp.random.seed(1002)\n",
        "parameters_fashion = init_parameters_nobias([60,20,10],input_shape=784)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF96GsscOJvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "49cd38fc-dd84-4f03-f523-cdb7909de1b5"
      },
      "source": [
        "ctr=0\n",
        "start_time = timeit.default_timer()\n",
        "for i in range(5): #epochs\n",
        "  for j in range(600): #number of batches to iterate.\n",
        "    \n",
        "    dparams=jit_backprop(parameters_fashion,fashion_train_data[ctr:ctr+100],fashion_train_labels[ctr:ctr+100]) #The last value is batch size\n",
        "    parameters_fashion= jit_update_weights(parameters_fashion,dparams,lr=0.01)\n",
        "    ctr=ctr+100\n",
        "    #print (j)\n",
        "    if ctr+100>60000:\n",
        "      ctr=0\n",
        "  pred=dense_jit(parameters_fashion,fashion_train_data[30000:30100])\n",
        "  pred=jnp.argmax(pred,axis=1)\n",
        "\n",
        "  targets=jnp.argmax(fashion_train_labels[30000:30100],axis=1)\n",
        "  print (f'epoch: ', i+1)\n",
        "  print(f'Validation Accuracy: ', len(jnp.where(pred == targets)[0])/100*100)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print (f'elapsed time: ', elapsed, 's')  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1\n",
            "Validation Accuracy:  83.0\n",
            "epoch:  2\n",
            "Validation Accuracy:  86.0\n",
            "epoch:  3\n",
            "Validation Accuracy:  87.0\n",
            "epoch:  4\n",
            "Validation Accuracy:  87.0\n",
            "epoch:  5\n",
            "Validation Accuracy:  87.0\n",
            "elapsed time:  11.376954624000064 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1elbHV1IlsN",
        "colab_type": "text"
      },
      "source": [
        "####Test For Fashion MNIST Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPrV25JrtuL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7556fe69-f4ce-41a5-f124-d1ece069cd5e"
      },
      "source": [
        "#full test: \n",
        "pred_1=dense_jit(parameters_fashion,fashion_test_data)\n",
        "pred_1=jnp.argmax(pred_1,axis=1)\n",
        "target_1=jnp.argmax(fashion_test_labels,axis=1)\n",
        "print(f'Test Accuracy:',len(jnp.where(pred_1 == target_1)[0])/10000 *100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 85.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzQRBvQoucZa",
        "colab_type": "text"
      },
      "source": [
        "###\"Stitch\" networks together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBj2bYVgujkW",
        "colab_type": "text"
      },
      "source": [
        "####Compose Parameters Function\n",
        "Function to concatenate the networks together and another matrix called $\\alpha$\n",
        "\n",
        "\n",
        "Function takes: \n",
        "\n",
        "$W^{params1}$\n",
        "$W^{params2}$\n",
        "\n",
        "Performs cross stitch using trainable parameter $\\alpha$ returns:\n",
        "\n",
        "\\\n",
        "$\n",
        "composed \\ parameters=\n",
        "\\begin{bmatrix} \n",
        "W^{params1} & \\alpha^{set1}\\\\\n",
        "\\alpha^{set2} & W^{params2}\\\\\n",
        "\\end{bmatrix}\n",
        "\\quad\n",
        "$\n",
        "\n",
        "This is done for all hidden layers, with the output layer being concatenated along one dimension\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I5rrUHWuVOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compose_parameters(params1,params2,alpha):\n",
        "  #Concatenate all bias. The final layer will not matter, the bias is set to 0, and is excluded in the last layer as output layer is concatenated along 0 axis. \n",
        "  layer0_cat_bias = jnp.concatenate([params1[0][1],params2[0][1]],axis=0)\n",
        "  layer1_cat_bias=jnp.concatenate([params1[1][1],params2[1][1]],axis=0) \n",
        "  layer2_cat_bias=params1[2][1]\n",
        "\n",
        "  #layer0: \n",
        "  layer0_cat = jnp.concatenate([params1[0][0],params2[0][0]],axis=0)\n",
        "  #layer1: \n",
        "  temp1=jnp.concatenate([params1[1][0],alpha[0][0]],axis=1) \n",
        "  temp2=jnp.concatenate([alpha[0][1],params2[1][0]],axis=1) \n",
        "  layer1_cat = jnp.concatenate([temp1,temp2],axis=0)\n",
        "  \n",
        "  #layer2 - Output Layer.\n",
        "  layer2_cat=jnp.concatenate([params1[2][0],params2[2][0]],axis=1)  #this will output a 10,40\n",
        "  \n",
        "  #put concatenations together into new parameters\n",
        "\n",
        "  new_parameters=[[]]\n",
        "  new_parameters[0].append(layer0_cat)\n",
        "  new_parameters[0].append(layer0_cat_bias)\n",
        "  new_parameters.append([])\n",
        "  new_parameters[1].append(layer1_cat) \n",
        "  new_parameters[1].append(layer1_cat_bias)\n",
        "  new_parameters.append([])\n",
        "  new_parameters[2].append(layer2_cat)\n",
        "  new_parameters[2].append(layer2_cat_bias)\n",
        "  return new_parameters"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tolt4vWjh8fD",
        "colab_type": "text"
      },
      "source": [
        "New loss function with the separate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40db_LBH37WT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function that takes parameters of both networks, and 'alpha' puts them together. \n",
        "def NLL_loss_alpha(params1,params2,alpha,i,t): \n",
        "  new_parameters=compose_parameters(params1,params2,alpha)\n",
        "  pred=jit(dense_network_list)(new_parameters,i)\n",
        "  final=(NLL)(pred,t)\n",
        "  return final"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kqx85uiUlQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradient_alpha=grad(NLL_loss_alpha,argnums=(2))\n",
        "\n",
        "vmap_backprop_alpha = vmap(gradient_alpha,in_axes=(None,None,None,0,0))\n",
        "\n",
        "\n",
        "def update_alpha(alpha_,dalpha,lr=1.0):\n",
        "  for i in range(len(alpha_)): #iterate through the layer. \n",
        "    alpha_[i][0]=alpha_[i][0]-(lr*jnp.sum(dalpha[i][0],axis=0))\n",
        "    alpha_[i][1]=alpha_[i][1]-(lr*jnp.sum(dalpha[i][1],axis=0))\n",
        "  return alpha_\n",
        "\n",
        "#dense_jit=jit(dense_network_list) #speed up\n",
        "jit_backprop=jit(vmap_backprop_alpha)\n",
        "jit_update_alpha=jit(update_alpha)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOtja0Rn7TgQ",
        "colab_type": "text"
      },
      "source": [
        "###Combine Data Sets to retrain network on both tasks\n",
        "Combined set has 120000 samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odu5fV6s7Nq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_sets = jnp.concatenate([mnist_train_data,fashion_train_data],axis=0)\n",
        "combined_labels=jnp.concatenate([mnist_train_labels,fashion_train_labels],axis=0)\n",
        "onp.random.seed(1500)\n",
        "shuf_combined_sets,shuf_combined_labels=shuffle(combined_sets,combined_labels)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtUMpm5E4Qzi",
        "colab_type": "text"
      },
      "source": [
        "###Initialize $\\alpha$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ9fyAXn4ODi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha=[[]]\n",
        "alpha[0].append(jnp.zeros((20,60)))\n",
        "alpha[0].append(jnp.zeros((20,60)))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQhoejuCUJLx",
        "colab_type": "text"
      },
      "source": [
        "###Retrain Combined Network, but only on 2000 samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBMpIzpoUIgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dead191c-2049-46af-d04d-b5c0f25cf155"
      },
      "source": [
        "\n",
        "ctr=0\n",
        "start_time = timeit.default_timer()\n",
        "for i in range(40): #epochs\n",
        "  for j in range(20): #number of batches to iterate.\n",
        "    \n",
        "    dalpha=jit_backprop(parameters_mnist,parameters_fashion,alpha,shuf_combined_sets[ctr:ctr+100],shuf_combined_labels[ctr:ctr+100])\n",
        " #The last value is batch size\n",
        "    alpha= jit_update_alpha(alpha,dalpha,lr=0.01) #lr has to be very small\n",
        "    ctr=ctr+100\n",
        "    #print (j)\n",
        "    if ctr+100>2000:\n",
        "      ctr=0\n",
        "  new_params=compose_parameters(parameters_mnist,parameters_fashion,alpha)\n",
        "  pred=dense_jit(new_params,fashion_train_data[30000:31000])\n",
        "  pred=jnp.argmax(pred,axis=1)\n",
        "\n",
        "  targets=jnp.argmax(fashion_train_labels[30000:31000],axis=1)\n",
        "  print (f'epoch: ', i+1)\n",
        "  print(f'Validation Accuracy: ', len(jnp.where(pred == targets)[0])/1000)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print (f'elapsed time: ', elapsed)  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:  1\n",
            "Validation Accuracy:  0.806\n",
            "epoch:  2\n",
            "Validation Accuracy:  0.825\n",
            "epoch:  3\n",
            "Validation Accuracy:  0.834\n",
            "epoch:  4\n",
            "Validation Accuracy:  0.838\n",
            "epoch:  5\n",
            "Validation Accuracy:  0.843\n",
            "epoch:  6\n",
            "Validation Accuracy:  0.848\n",
            "epoch:  7\n",
            "Validation Accuracy:  0.853\n",
            "epoch:  8\n",
            "Validation Accuracy:  0.851\n",
            "epoch:  9\n",
            "Validation Accuracy:  0.851\n",
            "epoch:  10\n",
            "Validation Accuracy:  0.852\n",
            "epoch:  11\n",
            "Validation Accuracy:  0.853\n",
            "epoch:  12\n",
            "Validation Accuracy:  0.853\n",
            "epoch:  13\n",
            "Validation Accuracy:  0.853\n",
            "epoch:  14\n",
            "Validation Accuracy:  0.855\n",
            "epoch:  15\n",
            "Validation Accuracy:  0.855\n",
            "epoch:  16\n",
            "Validation Accuracy:  0.853\n",
            "epoch:  17\n",
            "Validation Accuracy:  0.852\n",
            "epoch:  18\n",
            "Validation Accuracy:  0.851\n",
            "epoch:  19\n",
            "Validation Accuracy:  0.851\n",
            "epoch:  20\n",
            "Validation Accuracy:  0.85\n",
            "epoch:  21\n",
            "Validation Accuracy:  0.85\n",
            "epoch:  22\n",
            "Validation Accuracy:  0.85\n",
            "epoch:  23\n",
            "Validation Accuracy:  0.85\n",
            "epoch:  24\n",
            "Validation Accuracy:  0.85\n",
            "epoch:  25\n",
            "Validation Accuracy:  0.85\n",
            "epoch:  26\n",
            "Validation Accuracy:  0.85\n",
            "epoch:  27\n",
            "Validation Accuracy:  0.85\n",
            "epoch:  28\n",
            "Validation Accuracy:  0.85\n",
            "epoch:  29\n",
            "Validation Accuracy:  0.852\n",
            "epoch:  30\n",
            "Validation Accuracy:  0.853\n",
            "epoch:  31\n",
            "Validation Accuracy:  0.854\n",
            "epoch:  32\n",
            "Validation Accuracy:  0.854\n",
            "epoch:  33\n",
            "Validation Accuracy:  0.854\n",
            "epoch:  34\n",
            "Validation Accuracy:  0.854\n",
            "epoch:  35\n",
            "Validation Accuracy:  0.854\n",
            "epoch:  36\n",
            "Validation Accuracy:  0.855\n",
            "epoch:  37\n",
            "Validation Accuracy:  0.856\n",
            "epoch:  38\n",
            "Validation Accuracy:  0.856\n",
            "epoch:  39\n",
            "Validation Accuracy:  0.855\n",
            "epoch:  40\n",
            "Validation Accuracy:  0.856\n",
            "elapsed time:  9.903665120000369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIshugceXSSB",
        "colab_type": "text"
      },
      "source": [
        "###Examine Combined Network Accuracy for MNIST "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYYf2pa-XQb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "super_params=compose_parameters(parameters_mnist,parameters_fashion,alpha) #combine all parameters into a new set of parameters."
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ppo7ZZyXgOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c37535c-6e3d-4910-98c2-1199c063c160"
      },
      "source": [
        "pred_1=dense_jit(super_params,mnist_test_data)\n",
        "pred_1=jnp.argmax(pred_1,axis=1)\n",
        "target_1=jnp.argmax(mnist_test_labels,axis=1)\n",
        "print(f'Test Accuracy:',len(jnp.where(pred_1 == target_1)[0])/10000 *100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 93.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0K77L6kXuc1",
        "colab_type": "text"
      },
      "source": [
        "###Examine Combined Network Accuracy on Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcebS-D_XrWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff5aa2df-c73d-47c0-bafb-fdcd9ed011b7"
      },
      "source": [
        "pred_1=dense_jit(super_params,fashion_test_data)\n",
        "pred_1=jnp.argmax(pred_1,axis=1)\n",
        "target_1=jnp.argmax(fashion_test_labels,axis=1)\n",
        "print(f'Test Accuracy:',len(jnp.where(pred_1 == target_1)[0])/10000 *100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 84.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y64im7yd442",
        "colab_type": "text"
      },
      "source": [
        "##Results\n",
        "\n",
        "MNIST- Alone = 95.72%\n",
        "Fashion - Alone = 85.58%\n",
        "\n",
        "Combined with cross stitch  - MNIST data = 93.77% , Fashion MNIST data= 84.34% on 2000 samples of combined set of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsdSqXVFT5p5",
        "colab_type": "text"
      },
      "source": [
        "##Appendix \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mijglBP2IC_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#####Parameter of mnist:\n",
        "$$\n",
        "\\begin{bmatrix} \n",
        "w^{mnist}_{0,0} & w^{mnist}_{0,1} & ... & w^{mnist}_{0,j}  \\\\\n",
        "w^{mnist}_{1,0} & w^{mnist}_{1,1} & ... & w^{mnist}_{1,j}\\\\\n",
        "\\vdots & \\vdots & ... & \\vdots\\\\\n",
        "w^{mnist}_{i,0} & w^{mnist}_{i,1} & ... & w^{mnist}_{i,j} \\\\\n",
        "\\end{bmatrix}\n",
        "\\quad\n",
        "$$\n",
        "\n",
        "Parameter of fashion mnist:\n",
        "$$\n",
        "\\begin{bmatrix} \n",
        "w^{fashion}_{0,0} & w^{fashion}_{0,1} & ... & w^{fashion}_{0,j}  \\\\\n",
        "w^{fashion}_{1,0} & w^{fashion}_{1,1} & ... & w^{fashion}_{1,j}\\\\\n",
        "\\vdots & \\vdots & ... & \\vdots\\\\\n",
        "w^{fashion}_{i,0} & w^{fashion}_{i,1} & ... & w^{fashion}_{i,j} \\\\\n",
        "\\end{bmatrix}\n",
        "\\quad\n",
        "$$\n",
        "\n",
        "Full Cross Stitch:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix} \n",
        "w^{mnist}_{0,0} & w^{mnist}_{0,1} & ... & w^{mnist}_{0,j} & \\alpha^{set1}_{0,0} & \\alpha^{set1}_{0,1} & ... & \\alpha^{set1}_{0,j}  \\\\\n",
        "w^{mnist}_{1,0} & w^{mnist}_{1,1} & ... & w^{mnist}_{1,j} & \\alpha^{set1}_{1,0} & \\alpha^{set1}_{1,1} & ... & \\alpha^{set1}_{1,j} \\\\\n",
        "\\vdots & \\vdots & ... & \\vdots & \\vdots & \\vdots & ... & \\vdots\\\\\n",
        "w^{mnist}_{i,0} & w^{mnist}_{i,1} & ... & w^{mnist}_{i,j} & \\alpha^{set1}_{i,0} & \\alpha^{set1}_{i,1} & ... & \\alpha^{set1}_{i,j}  \\\\\n",
        "\\alpha^{set2}_{0,0} & \\alpha^{set2}_{0,1} & ... & \\alpha^{set2}_{0,j} &  w^{fashion}_{0,0} & w^{fashion}_{0,1} & ... & w^{fashion}_{0,j} \\\\\n",
        "\\alpha^{set2}_{1,0} & \\alpha^{set2}_{1,1} & ... & \\alpha^{set2}_{1,j} & w^{fashion}_{1,0} & w^{fashion}_{1,1} & ... & w^{fashion}_{1,j}\\\\\n",
        "\\vdots & \\vdots & ... & \\vdots &\\vdots & \\vdots & ... & \\vdots \\\\\n",
        "\\alpha^{set2}_{i,0} & \\alpha^{set2}_{i,1} & ... & \\alpha^{set2}_{i,j} & w^{fashion}_{i,0} & w^{fashion}_{i,1} & ... & w^{fashion}_{i,j}\\\\\n",
        "\\end{bmatrix}\n",
        "\\quad\n",
        "$$\n"
      ]
    }
  ]
}